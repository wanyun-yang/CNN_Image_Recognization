{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Wanyun_Yang.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "U7mrWoKdH0QZ",
        "outputId": "114b16ba-4a04-476b-9615-d691adfe6462",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import files, drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y2J_uSNROHbF",
        "outputId": "54f8348a-01b5-4d81-9931-ed5fd29c0c92",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# create/define a CNN model for handwriting digit recognition problem\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "class Net(nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "\n",
        "    super().__init__()\n",
        "\n",
        "    self.conv1 = nn.Conv2d(1,6,5)\n",
        "    self.pool = nn.MaxPool2d(2,2)\n",
        "    self.conv2 = nn.Conv2d(6,16,5)\n",
        "    self.fc1 = nn.Linear(16*4*4,120)\n",
        "    self.fc2 = nn.Linear(120,84)\n",
        "    self.fc3 = nn.Linear(84,10)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.pool(F.relu(self.conv1(x)))\n",
        "    x = self.pool(F.relu(self.conv2(x)))\n",
        "    x = x.view(-1,self.num_flat_features(x))\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = F.relu(self.fc2(x))\n",
        "    x = F.log_softmax(self.fc3(x))\n",
        "\n",
        "    return x\n",
        "    # x --> conv1 -->relu -->pooling -->conv2 --> relu -->pooling --> fully connected\n",
        "\n",
        "  def num_flat_features(self,x):\n",
        "    size = x.size()[1:]\n",
        "    num_features = 1\n",
        "    for s in size:\n",
        "      num_features *=s\n",
        "    return num_features\n",
        "\n",
        "net = Net().to(device)\n",
        "print(net)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Net(\n",
            "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (fc1): Linear(in_features=256, out_features=120, bias=True)\n",
            "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
            "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "35FKs-m2Svcz"
      },
      "source": [
        "import os\n",
        "import glob\n",
        "import numpy as np\n",
        "from skimage import io\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class MNISTDataset(Dataset):\n",
        "\n",
        "  def __init__(self, dir, transform=None):\n",
        "    self.dir = dir\n",
        "    self.transform = transform\n",
        "\n",
        "  def __len__(self):\n",
        "    files = glob.glob(self.dir+'/*.jpg')\n",
        "    return len(files)\n",
        "  \n",
        "  def __getitem__(self, idx):\n",
        "    if torch.is_tensor(idx):\n",
        "      idx = idx.tolist()\n",
        "\n",
        "    all_files = glob.glob(self.dir+'/*.jpg')\n",
        "    img_fname = os.path.join(self.dir, all_files[idx])\n",
        "    image = io.imread(img_fname)\n",
        "\n",
        "    digit = int(self.dir.split('/')[-1].strip())\n",
        "    label = np.array(digit)\n",
        "\n",
        "    instance = {'image':image,'label':label}\n",
        "\n",
        "    if self.transform:\n",
        "      instance = self.transform(instance)\n",
        "\n",
        "    return instance"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MtfFMQ3WU9Hk"
      },
      "source": [
        "from skimage import transform\n",
        "from torchvision import transforms,utils\n",
        "\n",
        "class Rescale(object):\n",
        "\n",
        "  def __init__(self, output_size):\n",
        "    assert isinstance(output_size,(int,tuple))\n",
        "    self.output_size = output_size\n",
        "\n",
        "  def __call__(self,sample):\n",
        "    image, label = sample['image'],sample['label']\n",
        "\n",
        "    h,w = image.shape[-2:]\n",
        "    if isinstance(self.output_size, int):\n",
        "      if h > w:\n",
        "        new_h, new_w = self.output_size*h/w, self.output_size\n",
        "      else:\n",
        "        new_h, new_w = self.output_size, self.output_size*w/h\n",
        "    else:\n",
        "      new_h, new_w = self.output_size\n",
        "\n",
        "    new_h, new_w = int(new_h),int(new_w)\n",
        "\n",
        "    new_image = transform.resize(image,(new_h, new_w))\n",
        "\n",
        "    return {'image': new_image, 'label': label}\n",
        "  \n",
        "class ToTensor(object):\n",
        "  def __call__(self, sample):\n",
        "    image, label = sample['image'],sample['label']\n",
        "    image = image.reshape((1, image.shape[0],image.shape[1]))\n",
        "    return {'image':torch.from_numpy(image),'label':torch.from_numpy(label)}\n",
        "\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zwDPnwG3Yq8a",
        "outputId": "bf04f39b-f8eb-45f6-bed6-27d5c3356c67",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# create train/val dataloader\n",
        "from torch.utils.data import random_split\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "list_datasets = []\n",
        "for i in range(10):\n",
        "  cur_ds = MNISTDataset('/content/drive/My Drive/MNIST/trainingset/' + str(i),transform=transforms.Compose([Rescale(28),ToTensor()]))\n",
        "  list_datasets.append(cur_ds)\n",
        "\n",
        "dataset = torch.utils.data.ConcatDataset(list_datasets)\n",
        "print(len(dataset))\n",
        "\n",
        "train_size = int(len(dataset)*0.7)\n",
        "val_size = len(dataset) - train_size\n",
        "train_dataset, val_dataset = random_split(dataset,[train_size,val_size])\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size, shuffle=True, num_workers=1)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size, shuffle=True,num_workers=1)\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "42000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QlrBcf09U_Xs",
        "outputId": "bb1adabe-4201-4a6d-d428-4b37e0eda2f0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "epochs = 5\n",
        "learning_rate = 1e-3\n",
        "optimizer = optim.Adam(net.parameters(),lr = learning_rate,weight_decay=1e-5)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  net.train()\n",
        "\n",
        "  running_loss = 0.0\n",
        "\n",
        "  for batch_idx, batch in enumerate(train_dataloader):\n",
        "    inputs, targets = batch['image'].to(device, dtype=torch.float),batch['label'].to(device,dtype = torch.long)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    predicted_outputs = net(inputs)\n",
        "    loss = criterion(predicted_outputs,targets)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    running_loss += loss.item()\n",
        "\n",
        "    if (batch_idx+1)%10 ==0:\n",
        "      print('epoch %d,batch %d, training loss: %.3f' % (epoch+1,batch_idx+1,running_loss/10))\n",
        "      running_loss = 0.0\n",
        "    \n",
        "  #validation\n",
        "  net.eval()\n",
        "\n",
        "  correct = [0.0]*10\n",
        "  total = [0.0]*10\n",
        "\n",
        "  with torch.np_grad():\n",
        "    for batch_idx, batch in enumerate(val_dataloader):\n",
        "      images, labels = batch['image'].to(device,dtype = torch.float),batch['label'].to(device,dtype=torch.long)\n",
        "      predicted_outputs = net(images)\n",
        "\n",
        "      _,predicted_labels = torch.max(predicted_outputs,1)\n",
        "      c=(predicted_labels == labels)\n",
        "\n",
        "      for i in range(len(labels)):\n",
        "        label = labels[i]\n",
        "        correct[label] += c[i].item()\n",
        "        total[label] +=1\n",
        "\n",
        "  for i in range(10):\n",
        "    print('\\t Validation accuracy for digit %d: %.2f'% (i,100*correct[i]/total[i]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:30: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 1,batch 10, training loss: 2.296\n",
            "epoch 1,batch 20, training loss: 2.268\n",
            "epoch 1,batch 30, training loss: 2.187\n",
            "epoch 1,batch 40, training loss: 1.968\n",
            "epoch 1,batch 50, training loss: 1.658\n",
            "epoch 1,batch 60, training loss: 1.191\n",
            "epoch 1,batch 70, training loss: 1.034\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}